<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Iman Asmardokht – Academic CV</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<style>
:root{
  --bg:#0b0d10;
  --card:#12161b;
  --ink:#e9edf3;
  --muted:#aeb6c2;
  --brand:#5bb1ff;
  --accent:#7ee7a7;
  --rule:#1c232b;
}
*{box-sizing:border-box}
html,body{margin:0}
body{
  background:linear-gradient(180deg,#0b0d10, #0d1116 40%, #0b0d10);
  color:var(--ink);
  font:16px/1.55 ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Arial,Apple Color Emoji,Segoe UI Emoji;
  -webkit-font-smoothing:antialiased;
  padding:32px 16px;
}
.wrapper{
  max-width:980px;margin:0 auto;
}
.header{
  background:radial-gradient(1200px 400px at 20% -10%, rgba(91,177,255,.12), transparent 60%),
             radial-gradient(1000px 400px at 100% -20%, rgba(126,231,167,.10), transparent 60%),
             var(--card);
  border:1px solid var(--rule);
  border-radius:24px;
  padding:28px;
  display:grid;
  grid-template-columns:1fr auto;
  gap:16px;
  box-shadow:0 10px 40px rgba(0,0,0,.35);
}
.name{
  font-size:28px;font-weight:800;letter-spacing:.2px;
}
.role{color:var(--muted);font-size:15px;margin-top:4px}
.tags{margin-top:12px;display:flex;flex-wrap:wrap;gap:8px}
.tag{
  border:1px solid var(--rule);
  background:#0e1318;
  color:#cfe7ff;
  padding:6px 10px;border-radius:999px;font-size:12px
}
.contact{
  display:flex;flex-direction:column;gap:8px;
  align-items:flex-end;justify-content:center
}
.contact a{color:var(--ink);text-decoration:none}
.contact a:hover{color:var(--brand)}
.grid{
  margin-top:22px;
  display:grid;
  grid-template-columns: 280px 1fr;
  gap:22px;
}
.card{
  background:var(--card);
  border:1px solid var(--rule);
  border-radius:20px;
  padding:20px;
  box-shadow:0 10px 30px rgba(0,0,0,.25);
}
.h{
  font-size:13px;text-transform:uppercase;letter-spacing:.16em;color:#9fb2c7;margin:0 0 14px;
}
.item{margin-bottom:14px}
.item:last-child{margin-bottom:0}
.kv{display:flex;gap:8px;align-items:baseline}
.k{width:120px;color:var(--muted);font-size:13px}
.v{font-weight:600}
.hr{height:1px;background:var(--rule);margin:14px 0}
.edu .degree{font-weight:700}
.edu .meta{color:var(--muted);font-size:14px;margin-top:4px}
.badges{display:flex;flex-wrap:wrap;gap:8px;margin-top:8px}
.badge{
  background:#0e141a;border:1px solid var(--rule);border-radius:10px;
  padding:6px 10px;font-size:12px;color:#d6e2f0
}
.list{margin:0;padding-left:18px}
.list li{margin:6px 0}
.two-col{
  display:grid;grid-template-columns:1fr 1fr;gap:16px
}
@media (max-width:900px){
  .grid{grid-template-columns:1fr}
  .contact{align-items:flex-start}
  .two-col{grid-template-columns:1fr}
}
@media print{
  body{background:#fff;color:#000;padding:0}
  .header,.card{box-shadow:none}
  .tag,.badge{border-color:#ddd;background:#fafafa;color:#000}
  :root{--rule:#ddd}
}
</style>
</head>
<body>
  <div class="wrapper">
    <section class="header">
      <div>
        <div class="name">Iman Asmardokht</div>
        <div class="role">M.Sc. Photogrammetry • R&D • Computer Vision • UAV Navigation</div>
        <div class="tags">
          <span class="tag">Python</span>
          <span class="tag">Computer Vision</span>
          <span class="tag">UAV / MAVLink</span>
          <span class="tag">CUDA</span>
          <span class="tag">C#</span>
          <span class="tag">Embedded (Jetson • Raspberry Pi)</span>
          <span class="tag">GIS / Mapping</span>
        </div>
      </div>
      <div class="contact">
        <div><a href="mailto:iasmardokht@gmail.com">iasmardokht@gmail.com</a></div>
        <div><a href="tel:+989362023173">+98 936 202 3173</a></div>
        <div>Tehran, Iran</div>
        <div>LinkedIn: Iman Asmardokht</div>
      </div>
    </section>

    <section class="grid" aria-label="content">
      <aside class="card">
        <h3 class="h">Profile</h3>
        <div class="item" style="text-align: justify;">
          R&D engineer and photogrammetry specialist with experience in computer vision, UAV autonomous navigation, and real‑time image processing. Comfortable across embedded platforms, mapping workflows, and full‑stack integration for mission planning and data products.
        </div>
        <div class="hr"></div>
        <h3 class="h">Skills</h3>
        <div class="badges">
          <span class="badge">Python</span>
          <div class="sub-badges"  style = "margin-left: 25px;" >
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">cv2</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">scikit-learn</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">scikit-image</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">pymavlink</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">socket / websockets</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">PySide6 / Qt / QML</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">tensorflow</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">keras</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">pytorch</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">torchvision</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">ultralytics (YOLO)</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">CUDA</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">pymilvus</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">flask</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">json</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">Kivy</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">pillow (PIL)</span>
            <span class="badge" style="display: inline-flex; flex-wrap: wrap; gap: 6px; margin-top: 2px;">threading</span>
          </div>

          <span class="badge">C#</span>
          <span class="badge">HTML / CSS / JavaScript</span>
          <span class="badge">Linux</span>
          <span class="badge">Autopilot</span>
          <span class="badge">Mission Planner</span>
          <span class="badge">Agisoft Metashape</span>
          <span class="badge">GeoServer</span>
          <span class="badge">ArcGIS / QGIS</span>
          <span class="badge">RTSP</span>
          <span class="badge">Gimbal / Camera Control</span>
          <span class="badge">AutoCAD</span>
          <span class="badge">Civil3D</span>
        </div>
        <div class="hr"></div>
        <h3 class="h">Languages</h3>
        <div class="item kv"><div class="k">Persian</div><div class="v">Native</div></div>
        <div class="item kv"><div class="k">English</div><div class="v">Intermediate (improving)</div></div>
      </aside>

      <main class="card">
        <h3 class="h">Education</h3>
        <div class="item edu">
          <div class="degree">M.Sc. in Photogrammetry</div>
          <div class="meta">University of Tehran • 2023–2026 (expected)</div>
        </div>
        <div class="item edu">
          <div class="degree">B.Sc. in Surveying Engineering</div>
          <div class="meta">University of Tehran • 2018–2023</div>
        </div>

        <div class="hr"></div>

        <h3 class="h">Thesis</h3>
        <div class="item">
          <strong>Road‑based and vision‑based navigation for UAVs:</strong> Terrain‑based navigation using aerial imagery.
        </div>

        <div class="hr"></div>

        <h3 class="h">Research Experience & Projects</h3>

        <ul class="list">
          <li>
            <span style="font-weight: bold; font-size: 18px; color: #3498db;">Autonomous UAV Navigation:</span>
            <ul>
              <li><b>Vision Base Navigation:</b>
                <ul>
                  <li>Terrain based navigation using aerial imagery</li>
                  <li>Using Google Satellite imagery for Library</li>
                  <li style="text-align: justify;">By finding similarities between the live stream image and Google satellite images or georeferenced orthomosaics of the area in which the UAV is flying, it is positioned and its automatic navigation is performed.</li>
                </ul>
              </li>
              <li><b>Road Base Navigation:</b>
                <ul>
                  <li>Road Detection and Tracking</li>
                  <li>Road Following for Navigation</li>
                  <li style="text-align: justify;">By using road detection and tracking, the road is kept  in the center of the live stream by applying corrections to the UAV, and this keeps the UAV always moving on the road and automatic navigation is performed.</li>
                </ul>
              </li>
              <li><b>Visual Teach & Repeat:</b>
                <ul>
                  <li style="text-align: justify;">Teaching phase: Using GPS and INS, features are identified along the route, and their coordinates are given and stored.</li>
                  <li style="text-align: justify;">Repeating phase: On the return route, the UAV position is determined and navigation is performed by finding similarities between the stored features that were given coordinates and the live camera stream.</li>
                  <li style="text-align: justify;">A route is taken using GPS/INS and as soon as GPS is lost, it automatically returns from the route taken.</li>
                </ul>
              </li>
              <li><b>LTE Navigation:</b>
                <ul>
                  <li style="text-align: justify;">Receiving signals from the contact towers, the signal includes an ID specific to each tower, signal strength, and tower type, which allows the module's distance from each tower to be calculated, and once the exact location of the towers is known, the UAV is positioned and automatic navigation is performed.</li>
                </ul>
              </li>
              <li><b>INS Navigation and Manual Correction:</b>
                <ul>
                  <li style="text-align: justify;">If the UAV does not have any positioning module, using its internal elements such as air speed, IMU, Barometer, Compass, which are EKF inputs, the UAV can have an estimate of its position and use it to navigate, but in this method, due to the presence of cumulative errors, the estimate will encounter problems after a while and will shift. If it is possible to send an image from the UAV to the user, over time, a correction to the shift created can be applied to the UAV using the image so that the cumulative errors become 0 and the work can be resumed.</li>
                </ul>
              </li>
            </ul>
          </li>

          <li>
            <span style="font-weight: bold; font-size: 18px; color: #3498db;">Image Correction</span>
            <ul>
              <li><b>Camera Calibration</b>
                <ul>
                  <li style="text-align: justify;">Calibrating optical cameras using chessboard, Circles Pattern, and ChArUco board</li>
                  <li style="text-align: justify;">Estimating camera matrix and lens distortion coefficients</li>
                  <li style="text-align: justify;">Undistorting images for real-time projects using distortion coefficients and camera matrices</li>
                </ul>
              </li>
              <li><b>Video Stabilization:</b>
                <ul>
                  <li style="text-align: justify;">Stabilizing the camera attached to the UAV using Roll, Pitch, and Yaw UAV</li>
                  <li style="text-align: justify;">The camera is very sensitive to the image rate sent and the data rate related to the IMU using only IMU information. Image Processing techniques are used to compensate for this sensitivity and reduce it.</li>
                </ul>
              </li>
              <li><b>Online Mosaicking</b>
                <ul>
                  <li style="text-align: justify;">Positioning consecutive frames relative to each other and integrating them into a black two-dimensional environment and displaying the main stream in real-time in its actual location</li>
                  <li style="text-align: justify;">Geo-referencing mosaicked images and displaying them on the map for real-time map updates using UAV coordinates, UAV angles, and camera gimbal angles</li>
                </ul>
              </li>
            </ul>
          </li>

          <li>
            <span style="font-weight: bold; font-size: 18px; color: #3498db;">Applied Recognition Using AI</span>
            <ul>
              <li><b>vehicles Detection</b>
                <ul>
                  <li style="text-align: justify;">vehicles detection using YOLO and training it with datasets with appropriate altitude for UAV detection</li>
                  <li style="text-align: justify;">High-accuracy vehicles speed estimation using image perspective resolution and a fixed length on the ground</li>
                  <li style="text-align: justify;">Lane detection of each passing vehicle and detection of vehicles driving in prohibited lanes</li>
                  <li style="text-align: justify;">Estimating the distance between vehicles and detecting vehicles that are a short distance apart relative to their speed</li>
                </ul>
              </li>
              <li><b>Face Recognition</b>
                <ul>
                  <li style="text-align: justify;">Facial recognition using a small number of photos of a person</li>
                  <li style="text-align: justify;">Software design to detect a person's permission to enter an environment that displays different streams from different cameras</li>
                </ul>
              </li>
            </ul>
          </li>


        <!-- <ul class="list">
          <li>Autonomous UAV navigation: vision‑based and road‑based methods; INS integration with EKF; Visual Teach & Repeat.</li>
          <li>Real‑time image stabilization and online mosaicking for aerial imagery.</li>
          <li>Computer vision applications: face recognition; vehicle speed estimation from video.</li>
          <li>MAVLink integrations; gimbal and camera stream control; RTSP pipelines.</li>
          <li>Embedded computing on NVIDIA Jetson and Raspberry Pi for onboard perception.</li>
          <li>Celestial‑ and LTE‑based navigation experiments for redundancy.</li>
          <li>Web/UI and networking components for ground control and data services.</li>
        </ul> -->

        <div class="hr"></div>

        <h3 class="h">Work Experience</h3>
        <div class="two-col">
          <div class="item">
            <strong>Research & Development</strong><br>
            2024–Present
            <ul class="list">
              <li style="text-align: justify;">Computer vision programmer and real-time processing of UAV aerial images</li>
              <li style="text-align: justify;">Design and programming for automated UAV navigation</li>
              <li style="text-align: justify;">Giving different commands to the autopilot to perform various tasks using the Raspberry Pi and Jetson boards</li>
              <li style="text-align: justify;">Creating various packets and exchanging information on the network using ground and air links to command the gimbal and camera</li>
              <li style="text-align: justify;">Detect and track objects using deep learning networks and AI solutions</li>
            </ul>
          </div>
          <div class="item">
            <strong>Surveying & Photogrammetry Engineer</strong><br>
            2018–2023
            <ul class="list">
              <li>Aerial mapping with drones and production of 3D urban models and orthomosaic of areas for map production</li>
              <li>DEM generation using drone before and after mining to calculate extraction volume</li>
              <li>Accurate mapping, design and drawing using GPS, Laica and leveling</li>
            </ul>
          </div>
        </div>
      </main>
    </section>
  </div>
</body>
</html>
